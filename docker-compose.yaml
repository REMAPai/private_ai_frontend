services:
#  ollama:
#    volumes:
#      - ollama:/root/.ollama
#    container_name: ollama
#    pull_policy: always
#    tty: true
#    restart: unless-stopped
#    image: ollama/ollama:${OLLAMA_DOCKER_TAG-latest}

  open-webui:
    build:
      context: .
      dockerfile: Dockerfile
#    image: ghcr.io/open-webui/open-webui:${WEBUI_DOCKER_TAG-main}
    # container_name: open-webui
    volumes:
      - open-webui:/app/backend/data
      # Mount your streamlit app into the container
      - ./streamlit_app.py:/app/streamlit_app.py:ro 
    ports:
      - ${OPEN_WEBUI_PORT-7042}:8080
      - ${STREAMLIT_PORT-8501}:8501
    environment:
      - 'WEBUI_SECRET_KEY='
      # Both apps now share this exact path locally within the container
      - 'DATABASE_URL=sqlite:////app/backend/data/webui.db'
      # Password for accessing Streamlit app
      - 'STREAMLIT_PASSWORD=${STREAMLIT_PASSWORD:-admin123}'
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped
    # This command runs Open WebUI in the background (&) and Streamlit in the foreground
    # Wait for Open WebUI to be ready before starting Streamlit
    command: >
      bash -c "echo 'Starting Open WebUI...' &&
      (bash /app/backend/start.sh &) &&
      echo 'Waiting for Open WebUI to be ready...' &&
      for i in {1..60}; do
        if curl -sf http://localhost:8080/health > /dev/null 2>&1; then
          echo 'Open WebUI is ready!' &&
          break
        fi
        echo 'Waiting for Open WebUI...' &&
        sleep 2
      done &&
      echo 'Starting Streamlit...' &&
      streamlit run /app/streamlit_app.py --server.port=8501 --server.address=0.0.0.0"


volumes:
  #ollama: {}
  open-webui: {}
